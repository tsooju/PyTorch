{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**2_3_LR_Variable_Autograd.ipynb**"
      ],
      "metadata": {
        "id": "IzFIiRzKKEwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Variable & Automatic Gradient Calculation**\n",
        "- Tensor vs Variable\n",
        "- Graph and Gradient"
      ],
      "metadata": {
        "id": "RwdiPfghKQNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # Facebook에서 개발함\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "XkuTSZFlKlKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Tensor vs Variable**\n",
        "\n",
        "1) Declaration "
      ],
      "metadata": {
        "id": "L59QVaFlLF4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tensor = torch.Tensor(3, 4)\n",
        "x_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65ztuLywLTer",
        "outputId": "9b1ca7db-e153-497d-ff8f-a5261501cb01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5172e-35, 0.0000e+00, 3.7835e-44, 0.0000e+00],\n",
              "        [       nan, 0.0000e+00, 1.3733e-14, 6.4069e+02],\n",
              "        [4.3066e+21, 1.1824e+22, 4.3066e+21, 6.3828e+28]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_variable = Variable(x_tensor)\n",
        "x_variable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VaNh3NcnLmCq",
        "outputId": "f78fb8c2-6dc7-4ef8-ad50-d21b859dfb72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5172e-35, 0.0000e+00, 3.7835e-44, 0.0000e+00],\n",
              "        [       nan, 0.0000e+00, 1.3733e-14, 6.4069e+02],\n",
              "        [4.3066e+21, 1.1824e+22, 4.3066e+21, 6.3828e+28]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Variable 은 Autogradient 가능함 \n",
        "Pytorch 0.4 이상 버전에서는 Tensor 에 \n",
        "Variable 이 통합되고, Variable 은 \n",
        "deprecated 됨. Tensor 만 사용함. \n",
        "\n",
        "2) Variables of a Variable"
      ],
      "metadata": {
        "id": "Agpex4x6L7wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  data 속성\n",
        "x_variable.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFD0VE9ZMsIz",
        "outputId": "13e097d5-2cf3-4da6-f77d-9e2b35b0134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.5172e-35, 0.0000e+00, 3.7835e-44, 0.0000e+00],\n",
              "        [       nan, 0.0000e+00, 1.3733e-14, 6.4069e+02],\n",
              "        [4.3066e+21, 1.1824e+22, 4.3066e+21, 6.3828e+28]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "# grad 속성 : 값에 대한 gradient\n",
        "# Variable 생성시 초기화되면서 , gradient 도 같이 정의됨\n",
        "print(x_variable.grad) # grad 없음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA5Zwd2SM8kN",
        "outputId": "4a86002d-9e2b-4d9f-8fb4-71d4b3bec0ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# requires_grad 속성 : 값에 대한 gradient 요구시 사용\n",
        "print(x_variable.requires_grad) # 속성값 확인 : False\n",
        "# gradient 가 계산이 안된 산태임\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNuUCLqNNgqx",
        "outputId": "45769468-a298-4643-a9b6-fa82a96bf607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient 에 대한 연산을 모두 추척함 : True\n",
        "x_variable = Variable(x_tensor, requires_grad=True)\n",
        "print(x_variable.requires_grad)\n",
        "print(x_variable.data)\n",
        "print(x_variable.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LduJfJ8gODua",
        "outputId": "60199203-e2ae-4fd4-edcb-87c135297ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "tensor([[1.5172e-35, 0.0000e+00, 3.7835e-44, 0.0000e+00],\n",
            "        [       nan, 0.0000e+00, 1.3733e-14, 6.4069e+02],\n",
            "        [4.3066e+21, 1.1824e+22, 4.3066e+21, 6.3828e+28]])\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# volatile 속성 : 최소 메모리 사용에 대한 설정\n",
        "# requires_grad 가 False 이면, volatile 도 자동 False 가 됨.\n",
        "x_variable = Variable(x_tensor, volatile=True)\n",
        "print(x_variable.grad)\n",
        "print(x_variable.volatile)\n",
        "print(x_variable.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2OCs5DqO1nh",
        "outputId": "fe2001f1-1736-40ba-ca9b-c7a60215cc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "False\n",
            "False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: volatile was removed (Variable.volatile is always False)\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Graph & Variables**\n"
      ],
      "metadata": {
        "id": "LCf2nDUnQHth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create graph\n",
        "x = Variable(torch.FloatTensor(3, 4), requires_grad=True)\n",
        "y = x**2 + 4*x\n",
        "z = 2*y + 3\n",
        "\n",
        "print(x.requires_grad)\n",
        "print(y.requires_grad)\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j6y-hl5QPQ5",
        "outputId": "093ddcaf-aeff-459d-af7d-ca3b47dc7d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# backward(gradient, retain_grad, create_grad, retain_variables)\n",
        "# 현재값 w, r, t, graph에 대한 gradient 계산 함수임\n",
        "# 역전파 알고리즘 적용 계산함수 \n",
        "\n",
        "# 위의 z 값으로 x의 gradient 를 계산해 냄. \n",
        "loss = torch.FloatTensor(3,4)\n",
        "z.backward(loss)\n",
        "\n",
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7KTdhgWVymg",
        "outputId": "b502c197-afce-46e4-ee1b-f19bd15f83f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "tensor([[1.2138e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "None\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  aten/src/ATen/core/TensorBody.h:477.)\n",
            "  return self._grad\n"
          ]
        }
      ]
    }
  ]
}